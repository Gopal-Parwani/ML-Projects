{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When only the last statement is considered\n",
    "- The best threshold for deciding whether it's gonna default or not is 0.3518\n",
    "- Accuracy = 0.8871\n",
    "- Precision = 0.7426\n",
    "- Recall = 0.8696\n",
    "- F1 Score = 0.8011\n",
    "- Amex Score = 0.7728\n",
    "- AUC = 0.9552\n",
    "- Normalized Weighted Gini = 0.9103\n",
    "- Percentage of total defaulters captured in Top Four Percent= 0.6354\n",
    "  \n",
    "  Note that these metrics are on validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When all the statements are aggregated\n",
    "- The best threshold for deciding whether it's gonna default or not is 0.3518\n",
    "- Accuracy = 0.8971\n",
    "- Precision = 0.7827\n",
    "- Recall = 0.8394\n",
    "- F1 Score = 0.8101\n",
    "- Amex Score = 0.7754\n",
    "- AUC = 0.9565\n",
    "- Normalized Weighted Gini = 0.9103\n",
    "- Percentage of total defaulters captured in Top Four Percent= 0.6378\n",
    "  \n",
    "  Note that these metrics are on validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:46:52.493554Z",
     "iopub.status.busy": "2025-12-20T12:46:52.493128Z",
     "iopub.status.idle": "2025-12-20T12:46:52.498383Z",
     "shell.execute_reply": "2025-12-20T12:46:52.497554Z",
     "shell.execute_reply.started": "2025-12-20T12:46:52.493528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:46:54.700217Z",
     "iopub.status.busy": "2025-12-20T12:46:54.699954Z",
     "iopub.status.idle": "2025-12-20T12:47:09.647686Z",
     "shell.execute_reply": "2025-12-20T12:47:09.646645Z",
     "shell.execute_reply.started": "2025-12-20T12:46:54.700199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ss_df = pd.read_csv('/kaggle/input/amex-default-prediction/sample_submission.csv', engine = 'python')\n",
    "train_labels = pd.read_csv('/kaggle/input/amex-default-prediction/train_labels.csv', engine = 'python')\n",
    "train_df1 = pd.read_csv('/kaggle/input/amex-default-prediction/train_data.csv', nrows=200_000) #contains header and first 200_000 data rows\n",
    "train_df2 = pd.read_csv('/kaggle/input/amex-default-prediction/train_data.csv', skiprows=range(1,200_000+1), nrows = 200_000) #contains header and data rows from 200_001 till and including 400_000\n",
    "train_df3 = pd.read_csv('/kaggle/input/amex-default-prediction/train_data.csv', skiprows=range(1,400_000+1), nrows=58913) #contains header and data rows from 400_001 till and including 458_913\n",
    "train_df1_2 = pd.concat([train_df1,train_df2], ignore_index = True)\n",
    "train_df = pd.DataFrame(pd.concat([train_df1_2, train_df3], ignore_index=True))\n",
    "cat_features = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# test_df1 = pd.read_csv('/kaggle/input/amex-default-prediction/test_data.csv', nrows=200_000)\n",
    "# test_df2 = pd.read_csv('/kaggle/input/amex-default-prediction/test_data.csv', skiprows=range(1,200_000+1), nrows=200_000)\n",
    "# test_df3 = pd.read_csv('/kaggle/input/amex-default-prediction/test_data.csv', skiprows=range(1,400_000+1), nrows=200_000)\n",
    "# test_df4 = pd.read_csv('/kaggle/input/amex-default-prediction/test_data.csv', skiprows=range(1,600_000+1), nrows=324_621)\n",
    "# test_df1_2 = pd.concat([test_df1, test_df2], ignore_index = True)\n",
    "# test_df3_4 = pd.concat([test_df3, test_df4], ignore_index = True)\n",
    "# test_df = pd.concat([test_df1_2, test_df3_4], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:25:37.200847Z",
     "iopub.status.busy": "2025-12-20T12:25:37.200560Z",
     "iopub.status.idle": "2025-12-20T12:25:37.206146Z",
     "shell.execute_reply": "2025-12-20T12:25:37.205222Z",
     "shell.execute_reply.started": "2025-12-20T12:25:37.200829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def denoise_numeric(df):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # numeric columns only\n",
    "    num_cols = df.select_dtypes(include=['float', 'int']).columns\n",
    "\n",
    "    for col in num_cols:\n",
    "\n",
    "        # Remove infinities\n",
    "        #df[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "        # Clip extreme outliers (standard Kaggle practice)\n",
    "        q1, q99 = df[col].quantile([0.01, 0.99])\n",
    "        df[col] = df[col].clip(q1, q99)\n",
    "\n",
    "        # Apply rounding / bucketing to reduce noise\n",
    "        # floor(x * 100) → keeps 2 decimal places\n",
    "        # You can change 100 to 1000 if you want more resolution.\n",
    "        df[col] = np.floor(df[col] * 100) / 100.0\n",
    "\n",
    "        # NA values remain NA — untouched\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:57:22.615228Z",
     "iopub.status.busy": "2025-12-19T17:57:22.614866Z",
     "iopub.status.idle": "2025-12-19T17:57:23.430793Z",
     "shell.execute_reply": "2025-12-19T17:57:23.430207Z",
     "shell.execute_reply.started": "2025-12-19T17:57:22.615148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_merged = train_df.merge(train_labels, on='customer_ID', how='left')\n",
    "train_merged.shape\n",
    "train_merged['target'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing data\n",
    "We will remove the columns for which the missing values are more than 50% using and also the 'customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:25:37.207803Z",
     "iopub.status.busy": "2025-12-20T12:25:37.207586Z",
     "iopub.status.idle": "2025-12-20T12:25:37.231130Z",
     "shell.execute_reply": "2025-12-20T12:25:37.230385Z",
     "shell.execute_reply.started": "2025-12-20T12:25:37.207787Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def CleanMissing(df, threshold):\n",
    "    # Drop the columns with missing fraction > criteria\n",
    "    cols_to_drop = df.columns[df.isna().mean() > threshold].tolist()\n",
    "    df_clear = df.drop(columns=cols_to_drop)\n",
    "    return df_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:54:37.138755Z",
     "iopub.status.busy": "2025-12-19T17:54:37.138048Z",
     "iopub.status.idle": "2025-12-19T17:54:37.640034Z",
     "shell.execute_reply": "2025-12-19T17:54:37.639483Z",
     "shell.execute_reply.started": "2025-12-19T17:54:37.138730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Drop the columns with missing fraction > 0.5\n",
    "cols_to_drop = train_merged.columns[train_merged.isna().mean() > 0.5].tolist()\n",
    "\n",
    "# Add customer_ID and S_2\n",
    "cols_to_drop += ['customer_ID', 'S_2']\n",
    "\n",
    "# Create the modified dataframe\n",
    "train_merged = train_merged.drop(columns=cols_to_drop)\n",
    "cat_features = [c for c in cat_features if c not in cols_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amex Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:25:37.232436Z",
     "iopub.status.busy": "2025-12-20T12:25:37.232218Z",
     "iopub.status.idle": "2025-12-20T12:25:37.250779Z",
     "shell.execute_reply": "2025-12-20T12:25:37.250207Z",
     "shell.execute_reply.started": "2025-12-20T12:25:37.232421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def amex_metric_xgb(preds, dtrain):\n",
    "    y_true = pd.DataFrame({\"target\": dtrain.get_label()})\n",
    "    y_pred = pd.DataFrame({\"prediction\": preds})\n",
    "    return \"amex\", amex_metric(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's do the hypertuning\n",
    "Since there are a lot of parameters to hypertune on, we will do it hypertuning over subset of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is not good. Let's try to train using last statement only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T04:19:03.202662Z",
     "iopub.status.busy": "2025-11-19T04:19:03.201981Z",
     "iopub.status.idle": "2025-11-19T04:19:12.443069Z",
     "shell.execute_reply": "2025-11-19T04:19:12.442310Z",
     "shell.execute_reply.started": "2025-11-19T04:19:03.202635Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#test_df = denoise_numeric(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:54:47.684051Z",
     "iopub.status.busy": "2025-12-19T17:54:47.683450Z",
     "iopub.status.idle": "2025-12-19T17:54:47.804614Z",
     "shell.execute_reply": "2025-12-19T17:54:47.804001Z",
     "shell.execute_reply.started": "2025-12-19T17:54:47.684027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_labels['customer_ID'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the columns you dropped in training dataset and declare the categorical varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:54:53.150068Z",
     "iopub.status.busy": "2025-12-19T17:54:53.149494Z",
     "iopub.status.idle": "2025-12-19T17:54:53.219422Z",
     "shell.execute_reply": "2025-12-19T17:54:53.218557Z",
     "shell.execute_reply.started": "2025-12-19T17:54:53.150045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cols_to_keep = X_train.columns\n",
    "X_test = test_df[cols_to_keep].copy()\n",
    "\n",
    "for c in cat_features:\n",
    "    X_test[c] = X_test[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T07:36:42.436782Z",
     "iopub.status.busy": "2025-11-19T07:36:42.436362Z",
     "iopub.status.idle": "2025-11-19T07:36:42.450929Z",
     "shell.execute_reply": "2025-11-19T07:36:42.449535Z",
     "shell.execute_reply.started": "2025-11-19T07:36:42.436753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 1. Align test columns\n",
    "# -----------------------\n",
    "cols_to_keep = X_train.columns\n",
    "X_test = test_df[cols_to_keep]\n",
    "\n",
    "for c in cat_features:\n",
    "    X_test[c] = X_test[c].astype(\"category\")\n",
    "\n",
    "# -----------------------\n",
    "# 2. Predict on test\n",
    "# -----------------------\n",
    "test_df['prediction'] = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# -----------------------\n",
    "# 3. Aggregate per customer_ID\n",
    "# -----------------------\n",
    "final_pred = (\n",
    "    test_df.groupby('customer_ID')['prediction']\n",
    "    .tail(1)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 4. Merge with sample submission to ensure correct order\n",
    "# -----------------------\n",
    "submission = ss_df[['customer_ID']].merge(\n",
    "    final_pred,\n",
    "    on='customer_ID',\n",
    "    how='right'\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 5. Safety: fill missing\n",
    "# -----------------------\n",
    "submission['prediction'].fillna(0.0, inplace=True)\n",
    "\n",
    "# -----------------------\n",
    "# 6. Save file\n",
    "# -----------------------\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The amex metric for the test data is around 0.04, which means that our model is not performing good on the test data like it was doing\n",
    "### on the validation data. The reason is that the validation data had the data for the same customer_IDs as were there in the training dataset\n",
    "### and they must be correlated somehow as they are the data form a time series. The test data also has a time series data as there are 924621 entries, but \n",
    "### only 75231 unique columns. Let's train only the on the the last statement of the training dataset and predict using\n",
    "### the last statement of the dataset and fill the same target values for the all the statements for that customer - this sounds wrong because initially a customer's features might be good\n",
    "### and could get worse so the prediction in the test and validation data should be according to each statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:56:50.823580Z",
     "iopub.status.busy": "2025-12-19T17:56:50.823270Z",
     "iopub.status.idle": "2025-12-19T17:56:51.453716Z",
     "shell.execute_reply": "2025-12-19T17:56:51.452933Z",
     "shell.execute_reply.started": "2025-12-19T17:56:50.823558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_last = (\n",
    "    train_df\n",
    "    .groupby(\"customer_ID\")\n",
    "    .last()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T17:55:45.193957Z",
     "iopub.status.idle": "2025-12-19T17:55:45.194285Z",
     "shell.execute_reply": "2025-12-19T17:55:45.194120Z",
     "shell.execute_reply.started": "2025-12-19T17:55:45.194105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:57:39.952772Z",
     "iopub.status.busy": "2025-12-19T17:57:39.952242Z",
     "iopub.status.idle": "2025-12-19T17:57:40.080041Z",
     "shell.execute_reply": "2025-12-19T17:57:40.079403Z",
     "shell.execute_reply.started": "2025-12-19T17:57:39.952751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_last_merged = train_last.merge(train_labels, on='customer_ID', how='left')\n",
    "train_last_merged.shape\n",
    "train_last_merged['target'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:57:42.246509Z",
     "iopub.status.busy": "2025-12-19T17:57:42.246243Z",
     "iopub.status.idle": "2025-12-19T17:57:42.294790Z",
     "shell.execute_reply": "2025-12-19T17:57:42.294033Z",
     "shell.execute_reply.started": "2025-12-19T17:57:42.246489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Drop the columns with missing fraction > 0.5\n",
    "cols_to_drop = train_last_merged.columns[train_last_merged.isna().mean() > 0.5].tolist()\n",
    "\n",
    "# Add customer_ID and S_2\n",
    "cols_to_drop += ['customer_ID', 'S_2']\n",
    "\n",
    "# Create the modified dataframe\n",
    "train_last_merged = train_last_merged.drop(columns=cols_to_drop)\n",
    "cat_features = [c for c in cat_features if c not in cols_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:57:44.513780Z",
     "iopub.status.busy": "2025-12-19T17:57:44.513256Z",
     "iopub.status.idle": "2025-12-19T17:57:44.574691Z",
     "shell.execute_reply": "2025-12-19T17:57:44.573905Z",
     "shell.execute_reply.started": "2025-12-19T17:57:44.513757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = train_last_merged.drop(columns=['target']).copy()\n",
    "for c in cat_features:\n",
    "    X[c] = X[c].astype('category')\n",
    "y = train_last_merged['target'].copy()\n",
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T17:57:47.860643Z",
     "iopub.status.busy": "2025-12-19T17:57:47.860391Z",
     "iopub.status.idle": "2025-12-19T17:57:47.910751Z",
     "shell.execute_reply": "2025-12-19T17:57:47.909840Z",
     "shell.execute_reply.started": "2025-12-19T17:57:47.860625Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#denoise the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:30:33.716726Z",
     "iopub.status.busy": "2025-12-19T18:30:33.715940Z",
     "iopub.status.idle": "2025-12-19T18:53:57.357523Z",
     "shell.execute_reply": "2025-12-19T18:53:57.356671Z",
     "shell.execute_reply.started": "2025-12-19T18:30:33.716699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "trial_history = []\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"missing\": np.nan,\n",
    "        \"enable_categorical\": True,\n",
    "        \"n_estimators\": 400,\n",
    "\n",
    "        # ---- Parameters to tune ----\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 8, 80, step=8),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 10, 100, step=10),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.05, 0.1]),\n",
    "        \"subsample\": trial.suggest_categorical(\"subsample\", [0.3, 0.4, 0.5, 0.8, 1.0]),\n",
    "        \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", [0.5, 0.8, 1.0]),\n",
    "        \n",
    "\n",
    "        # ---- Regularization tuning ----\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 5, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # predictions\n",
    "    preds = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    # Compute AMEX\n",
    "    y_true_df = pd.DataFrame({'target': y_valid}).reset_index(drop=True)\n",
    "    y_pred_df = pd.DataFrame({'prediction': preds}).reset_index(drop=True)\n",
    "\n",
    "    score = amex_metric(y_true_df, y_pred_df)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # SAVE TRIAL RESULTS SAFELY\n",
    "    # ----------------------------\n",
    "    trial_history.append({\n",
    "        \"params\": params.copy(),              # <-- IMPORTANT FIX\n",
    "        \"best_iteration\": model.best_iteration,\n",
    "        \"amex_score\": score\n",
    "    })\n",
    "    \n",
    "    return score  # Optuna will maximize the AMEX metric\n",
    "\n",
    "\n",
    "# Run study\n",
    "study = optuna.create_study(\n",
    "    study_name=\"xgb_amex_gpu\",\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///optuna_xgb.db\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=300)  # adds 300 more\n",
    "\n",
    "# Convert to DataFrame\n",
    "trial_df = pd.DataFrame(trial_history)\n",
    "\n",
    "# Flatten params dict into columns (optional but very useful!)\n",
    "trial_df = trial_df.join(trial_df[\"params\"].apply(pd.Series)).drop(columns=[\"params\"])\n",
    "\n",
    "trial_df.sort_values(\"amex_score\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"Best AMEX:\", study.best_trial.value)\n",
    "print(\"Best Params:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:59:43.637111Z",
     "iopub.status.busy": "2025-12-19T18:59:43.636652Z",
     "iopub.status.idle": "2025-12-19T18:59:43.701176Z",
     "shell.execute_reply": "2025-12-19T18:59:43.700570Z",
     "shell.execute_reply.started": "2025-12-19T18:59:43.637087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "trial_df = pd.DataFrame(trial_history)\n",
    "\n",
    "# Flatten params dict into columns (optional but very useful!)\n",
    "trial_df = trial_df.join(trial_df[\"params\"].apply(pd.Series)).drop(columns=[\"params\"])\n",
    "\n",
    "trial_df.sort_values(\"amex_score\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"Best AMEX:\", study.best_trial.value)\n",
    "print(\"Best Params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T18:59:52.432400Z",
     "iopub.status.busy": "2025-12-19T18:59:52.431801Z",
     "iopub.status.idle": "2025-12-19T18:59:53.792064Z",
     "shell.execute_reply": "2025-12-19T18:59:53.791370Z",
     "shell.execute_reply.started": "2025-12-19T18:59:52.432376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for col in ['max_depth', 'min_child_weight', 'learning_rate', 'subsample', \n",
    "            'colsample_bytree', 'n_estimators', 'lambda', 'alpha', 'gamma']:\n",
    "    \n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.scatterplot(data=trial_df, x=col, y='amex_score')\n",
    "    plt.title(f'{col} vs AMEX')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# The following values of bes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T04:49:06.551652Z",
     "iopub.status.busy": "2025-11-19T04:49:06.549957Z",
     "iopub.status.idle": "2025-11-19T04:54:43.023356Z",
     "shell.execute_reply": "2025-11-19T04:54:43.022464Z",
     "shell.execute_reply.started": "2025-11-19T04:49:06.551613Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# trial_history2 = []\n",
    "\n",
    "# def objective(trial):\n",
    "\n",
    "#     params = {\n",
    "#         \"objective\": \"binary:logistic\",\n",
    "#         \"tree_method\": \"hist\",\n",
    "#         \"eval_metric\": \"auc\",\n",
    "#         \"missing\": np.nan,\n",
    "#         \"enable_categorical\": True,\n",
    "\n",
    "#         # ---- tuned params ----\n",
    "#         \"max_depth\": 40,\n",
    "#         \"min_child_weight\": 30,\n",
    "#         \"learning_rate\":0.05,\n",
    "#         \"subsample\": 1.0,\n",
    "#         \"colsample_bytree\": 0.5,\n",
    "#         \"n_estimators\": 400,\n",
    "#         \"alpha\": 0,\n",
    "\n",
    "#         # ---- Regularization tuning ----\n",
    "#         \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 7, log=True),\n",
    "#         \"gamma\": trial.suggest_float(\"gamma\", 0, 4),\n",
    "#     }\n",
    "\n",
    "#     model = xgb.XGBClassifier(**params)\n",
    "\n",
    "#     model.fit(\n",
    "#         X_train, y_train,\n",
    "#         eval_set=[(X_valid, y_valid)],\n",
    "#         early_stopping_rounds=30,\n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "#     # predictions\n",
    "#     preds = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "#     # Compute AMEX\n",
    "#     y_true_df = pd.DataFrame({'target': y_valid}).reset_index(drop=True)\n",
    "#     y_pred_df = pd.DataFrame({'prediction': preds}).reset_index(drop=True)\n",
    "\n",
    "#     score = amex_metric(y_true_df, y_pred_df)\n",
    "    \n",
    "#     # ----------------------------\n",
    "#     # SAVE TRIAL RESULTS SAFELY\n",
    "#     # ----------------------------\n",
    "#     trial_history2.append({\n",
    "#         \"params\": params.copy(),              # <-- IMPORTANT FIX\n",
    "#         \"best_iteration\": model.best_iteration,\n",
    "#         \"amex_score\": score\n",
    "#     })\n",
    "    \n",
    "#     return score  # Optuna will maximize the AMEX metric\n",
    "\n",
    "\n",
    "# # Run study\n",
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=50)\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# trial2_df = pd.DataFrame(trial_history2)\n",
    "\n",
    "# # Flatten params dict into columns (optional but very useful!)\n",
    "# trial2_df = trial2_df.join(trial2_df[\"params\"].apply(pd.Series)).drop(columns=[\"params\"])\n",
    "\n",
    "# trial2_df.sort_values(\"amex_score\", ascending=False, inplace=True)\n",
    "\n",
    "# print(\"Best AMEX:\", study.best_trial.value)\n",
    "# print(\"Best Params:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha is cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:11:28.616344Z",
     "iopub.status.busy": "2025-12-19T19:11:28.615945Z",
     "iopub.status.idle": "2025-12-19T19:11:34.618733Z",
     "shell.execute_reply": "2025-12-19T19:11:34.615714Z",
     "shell.execute_reply.started": "2025-12-19T19:11:28.616319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from xgboost.callback import EarlyStopping\n",
    "\n",
    "best_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"missing\": np.nan,\n",
    "    \"enable_categorical\": True,\n",
    "\n",
    "    # tuned params\n",
    "    \"max_depth\": 80,\n",
    "    \"min_child_weight\": 40,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"n_estimators\": 1000,   # LARGE ON PURPOSE\n",
    "    \"lambda\": 0.007670118758441345,\n",
    "    \"alpha\": 0.09157175965761555,\n",
    "    \"gamma\": 1.028865262384579,\n",
    "}\n",
    "\n",
    "best_xgb = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "best_xgb.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_metric=\"auc\",  # REQUIRED for early stopping\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            rounds=50,           # patience\n",
    "            save_best=True,      # keep best trees\n",
    "            maximize=True\n",
    "        )\n",
    "    ],\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:11:53.453053Z",
     "iopub.status.busy": "2025-12-19T19:11:53.452458Z",
     "iopub.status.idle": "2025-12-19T19:11:53.543501Z",
     "shell.execute_reply": "2025-12-19T19:11:53.542887Z",
     "shell.execute_reply.started": "2025-12-19T19:11:53.453030Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preds = best_xgb.predict_proba(X_valid)[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:20:21.061364Z",
     "iopub.status.busy": "2025-12-20T15:20:21.060595Z",
     "iopub.status.idle": "2025-12-20T15:20:21.069003Z",
     "shell.execute_reply": "2025-12-20T15:20:21.068407Z",
     "shell.execute_reply.started": "2025-12-20T15:20:21.061335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "    df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "          .sort_values('prediction', ascending=False))\n",
    "    df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "    four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "    df['weight_cumsum'] = df['weight'].cumsum()\n",
    "    df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "    return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "    \n",
    "def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "    df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "          .sort_values('prediction', ascending=False))\n",
    "    df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "    df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "    total_pos = (df['target'] * df['weight']).sum()\n",
    "    df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "    df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "    df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "    return df['gini'].sum()\n",
    "\n",
    "def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "    y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "    return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:11:57.344367Z",
     "iopub.status.busy": "2025-12-19T19:11:57.344065Z",
     "iopub.status.idle": "2025-12-19T19:11:57.349095Z",
     "shell.execute_reply": "2025-12-19T19:11:57.348496Z",
     "shell.execute_reply.started": "2025-12-19T19:11:57.344345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame({'prediction': preds}).reset_index(drop=True)\n",
    "y_true = pd.DataFrame({'target': y_valid}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:11:59.072480Z",
     "iopub.status.busy": "2025-12-19T19:11:59.071757Z",
     "iopub.status.idle": "2025-12-19T19:11:59.097772Z",
     "shell.execute_reply": "2025-12-19T19:11:59.097181Z",
     "shell.execute_reply.started": "2025-12-19T19:11:59.072455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "g = normalized_weighted_gini(y_true, y_pred)\n",
    "d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "print(g, d, 0.5 * (g + d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:12:10.154561Z",
     "iopub.status.busy": "2025-12-19T19:12:10.154297Z",
     "iopub.status.idle": "2025-12-19T19:12:10.402614Z",
     "shell.execute_reply": "2025-12-19T19:12:10.401965Z",
     "shell.execute_reply.started": "2025-12-19T19:12:10.154541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# 1. Predictions from your trained model\n",
    "preds = best_xgb.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "# 2. Choose threshold\n",
    "threshold = 0.5  # or any value you want (tuned threshold)\n",
    "\n",
    "# 3. Convert probabilities → binary labels\n",
    "y_pred_label = (preds >= threshold).astype(int)\n",
    "\n",
    "# 4. Compute confusion matrix\n",
    "cm = confusion_matrix(y_valid, y_pred_label)\n",
    "\n",
    "# 5. Plot\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix (threshold={threshold})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:12:24.862837Z",
     "iopub.status.busy": "2025-12-19T19:12:24.862289Z",
     "iopub.status.idle": "2025-12-19T19:12:24.952031Z",
     "shell.execute_reply": "2025-12-19T19:12:24.951311Z",
     "shell.execute_reply.started": "2025-12-19T19:12:24.862815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preds = best_xgb.predict_proba(X_valid)[:, 1]\n",
    "y_true = y_valid  # 0/1 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:14:27.094728Z",
     "iopub.status.busy": "2025-12-19T19:14:27.094136Z",
     "iopub.status.idle": "2025-12-19T19:14:28.286912Z",
     "shell.execute_reply": "2025-12-19T19:14:28.286217Z",
     "shell.execute_reply.started": "2025-12-19T19:14:27.094702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "thresholds = np.linspace(0.0, 1.0, 200)\n",
    "scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_label = (preds >= t).astype(int)\n",
    "    scores.append(f1_score(y_true, y_pred_label))\n",
    "\n",
    "best_idx = np.argmax(scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = scores[best_idx]\n",
    "\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "print(\"Best F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:14:29.849386Z",
     "iopub.status.busy": "2025-12-19T19:14:29.848674Z",
     "iopub.status.idle": "2025-12-19T19:14:30.006847Z",
     "shell.execute_reply": "2025-12-19T19:14:30.006205Z",
     "shell.execute_reply.started": "2025-12-19T19:14:29.849359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_true, preds)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision–Recall Curve\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:14:33.198936Z",
     "iopub.status.busy": "2025-12-19T19:14:33.198404Z",
     "iopub.status.idle": "2025-12-19T19:14:33.362186Z",
     "shell.execute_reply": "2025-12-19T19:14:33.361630Z",
     "shell.execute_reply.started": "2025-12-19T19:14:33.198915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_true, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:14:35.888483Z",
     "iopub.status.busy": "2025-12-19T19:14:35.887914Z",
     "iopub.status.idle": "2025-12-19T19:14:39.693000Z",
     "shell.execute_reply": "2025-12-19T19:14:39.692405Z",
     "shell.execute_reply.started": "2025-12-19T19:14:35.888461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_label = (preds >= t).astype(int)\n",
    "    precisions.append(precision_score(y_true, y_pred_label))\n",
    "    recalls.append(recall_score(y_true, y_pred_label))\n",
    "    f1s.append(f1_score(y_true, y_pred_label))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(thresholds, precisions, label=\"Precision\")\n",
    "plt.plot(thresholds, recalls, label=\"Recall\")\n",
    "plt.plot(thresholds, f1s, label=\"F1 Score\")\n",
    "plt.axvline(best_threshold, color='black', linestyle='--', label=f\"Best t={best_threshold:.3f}\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Threshold Tuning Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:14:42.561685Z",
     "iopub.status.busy": "2025-12-19T19:14:42.561423Z",
     "iopub.status.idle": "2025-12-19T19:14:42.711642Z",
     "shell.execute_reply": "2025-12-19T19:14:42.710998Z",
     "shell.execute_reply.started": "2025-12-19T19:14:42.561665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred_best = (preds >= best_threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_best)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix (Best threshold = {best_threshold:.3f})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:14:52.502426Z",
     "iopub.status.busy": "2025-12-19T19:14:52.501750Z",
     "iopub.status.idle": "2025-12-19T19:14:52.529801Z",
     "shell.execute_reply": "2025-12-19T19:14:52.529196Z",
     "shell.execute_reply.started": "2025-12-19T19:14:52.502401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Convert probabilities to labels\n",
    "y_pred_best = (preds >= best_threshold).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred_best)\n",
    "prec = precision_score(y_true, y_pred_best)\n",
    "rec = recall_score(y_true, y_pred_best)\n",
    "f1 = f1_score(y_true, y_pred_best)\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold:.4f}\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When only the last statement is considered\n",
    "- The best threshold for deciding whether it's gonna default or not is 0.3518\n",
    "- Accuracy = 0.8871\n",
    "- Precision = 0.7426\n",
    "- Recall = 0.8696\n",
    "- F1 Score = 0.8011\n",
    "- Amex Score = 0.7728\n",
    "- Normalized Weighted Gini = 0.9103\n",
    "- Percentage of total defaulters captured in Top Four Percent= 0.6354\n",
    "  \n",
    "  Note that these metrics are on validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:15:04.843147Z",
     "iopub.status.busy": "2025-12-19T19:15:04.842600Z",
     "iopub.status.idle": "2025-12-19T19:15:06.845893Z",
     "shell.execute_reply": "2025-12-19T19:15:06.845220Z",
     "shell.execute_reply.started": "2025-12-19T19:15:04.843124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "thresholds = np.linspace(0.0, 1.0, 101)\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred = (preds > t).astype(int)\n",
    "    precision_list.append(precision_score(y_valid, y_pred))\n",
    "    recall_list.append(recall_score(y_valid, y_pred))\n",
    "    f1_list.append(f1_score(y_valid, y_pred))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, precision_list, label=\"Precision\")\n",
    "plt.plot(thresholds, recall_list, label=\"Recall\")\n",
    "plt.plot(thresholds, f1_list, label=\"F1 Score\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Threshold Tuning Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:43:34.565378Z",
     "iopub.status.busy": "2025-12-20T12:43:34.564690Z",
     "iopub.status.idle": "2025-12-20T12:43:34.577349Z",
     "shell.execute_reply": "2025-12-20T12:43:34.576512Z",
     "shell.execute_reply.started": "2025-12-20T12:43:34.565353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_last = (\n",
    "    test_df\n",
    "    .groupby(\"customer_ID\")\n",
    "    .apply(lambda x: x.sort_values(\"S_2\").iloc[-1])\n",
    "    .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df['customer_ID'].unique().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:15:46.646148Z",
     "iopub.status.busy": "2025-12-19T19:15:46.645542Z",
     "iopub.status.idle": "2025-12-19T19:15:46.659203Z",
     "shell.execute_reply": "2025-12-19T19:15:46.658106Z",
     "shell.execute_reply.started": "2025-12-19T19:15:46.646123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 1. Align test columns\n",
    "# -----------------------\n",
    "cols_to_keep = X_train.columns\n",
    "X_test = test_last[cols_to_keep].copy()\n",
    "\n",
    "for c in cat_features:\n",
    "    X_test[c] = X_test[c].astype(\"category\")\n",
    "\n",
    "# -----------------------\n",
    "# 2. Predict on test\n",
    "# -----------------------\n",
    "test_last['prediction'] = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# -----------------------\n",
    "# 3. Merge with sample submission (correct order)\n",
    "# -----------------------\n",
    "submission = ss_df[['customer_ID']].merge(\n",
    "    test_last[['customer_ID', 'prediction']],\n",
    "    on='customer_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# 4. Safety\n",
    "# -----------------------\n",
    "submission['prediction'].fillna(0.0, inplace=True)\n",
    "\n",
    "# -----------------------\n",
    "# 5. Save file\n",
    "# -----------------------\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating all the columns for a customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T19:42:09.064446Z",
     "iopub.status.busy": "2025-12-19T19:42:09.063792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df['customer_ID'].unique().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:25:50.006516Z",
     "iopub.status.busy": "2025-12-20T12:25:50.005941Z",
     "iopub.status.idle": "2025-12-20T12:26:54.358257Z",
     "shell.execute_reply": "2025-12-20T12:26:54.357363Z",
     "shell.execute_reply.started": "2025-12-20T12:25:50.006493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = train_df.copy()\n",
    "uninclude_cols = [\"customer_ID\", \"S_2\"]\n",
    "\n",
    "# -----------------------------------\n",
    "# Explicit categorical columns\n",
    "# -----------------------------------\n",
    "cat_cols = [\n",
    "    'B_30', 'B_38', 'D_114', 'D_116', 'D_117', \n",
    "    'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68'\n",
    "]\n",
    "\n",
    "# Everything else except customer_ID, S_2, categorical = numeric\n",
    "num_cols = [c for c in df.columns if c not in cat_cols and c not in uninclude_cols]\n",
    "\n",
    "# Convert numericals safely\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# -----------------------------------\n",
    "# Aggregation specs\n",
    "# -----------------------------------\n",
    "num_aggs = ['mean', 'std', 'min', 'max', 'last']\n",
    "\n",
    "cat_aggs = [\n",
    "    ('last', 'last'),\n",
    "    ('mode', lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else np.nan),\n",
    "    ('nunique', 'nunique')\n",
    "]\n",
    "\n",
    "# Build agg dict\n",
    "agg_dict = {}\n",
    "\n",
    "for col in num_cols:\n",
    "    agg_dict[col] = num_aggs\n",
    "\n",
    "for col in cat_cols:\n",
    "    agg_dict[col] = cat_aggs\n",
    "\n",
    "# -----------------------------------\n",
    "# Groupby aggregation\n",
    "# -----------------------------------\n",
    "df_sorted = df.sort_values([\"customer_ID\", \"S_2\"])\n",
    "df_agg = df_sorted.groupby(\"customer_ID\").agg(agg_dict)\n",
    "\n",
    "\n",
    "\n",
    "# flatten names\n",
    "df_agg.columns = [f\"{c[0]}_{c[1]}\" for c in df_agg.columns]\n",
    "df_agg.reset_index(inplace=True)\n",
    "\n",
    "# need to make category datatype for the appropriate aggregated columns\n",
    "agg_cat_cols = [\n",
    "    c for c in df_agg.columns\n",
    "    if any(cat in c for cat in cat_cols)\n",
    "    and not c.endswith(\"_nunique\")\n",
    "]\n",
    "\n",
    "for col in agg_cat_cols:\n",
    "    df_agg[col] = df_agg[col].astype(\"category\")\n",
    "\n",
    "print(df_agg.shape)\n",
    "print([c for c in df_agg.columns if \"mode\" in c])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the importance of feature before dropping the features with a lot of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:26:54.359691Z",
     "iopub.status.busy": "2025-12-20T12:26:54.359393Z",
     "iopub.status.idle": "2025-12-20T12:26:54.625621Z",
     "shell.execute_reply": "2025-12-20T12:26:54.625001Z",
     "shell.execute_reply.started": "2025-12-20T12:26:54.359663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_agg_merged = df_agg.merge(train_labels, on = \"customer_ID\", how =\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:53:59.642568Z",
     "iopub.status.busy": "2025-12-20T12:53:59.641821Z",
     "iopub.status.idle": "2025-12-20T12:53:59.942273Z",
     "shell.execute_reply": "2025-12-20T12:53:59.941465Z",
     "shell.execute_reply.started": "2025-12-20T12:53:59.642539Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train validation split\n",
    "X = df_agg_merged.drop(columns=[\"target\", \"customer_ID\"])\n",
    "y = df_agg_merged [\"target\"]\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:52:10.678645Z",
     "iopub.status.busy": "2025-12-20T12:52:10.677963Z",
     "iopub.status.idle": "2025-12-20T12:52:10.770307Z",
     "shell.execute_reply": "2025-12-20T12:52:10.769765Z",
     "shell.execute_reply.started": "2025-12-20T12:52:10.678617Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "missing_frac = X_train.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:54:07.826638Z",
     "iopub.status.busy": "2025-12-20T12:54:07.826288Z",
     "iopub.status.idle": "2025-12-20T12:55:01.947604Z",
     "shell.execute_reply": "2025-12-20T12:55:01.946917Z",
     "shell.execute_reply.started": "2025-12-20T12:54:07.826608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#This model is only to find the importance of features\n",
    "\n",
    "base_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"missing\": np.nan,\n",
    "    \"enable_categorical\": True,\n",
    "    \"device\": \"cuda\",\n",
    "\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 8,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"eval_metric\": \"auc\"\n",
    "}\n",
    "\n",
    "base_model = xgb.XGBClassifier(\n",
    "    **base_params,\n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "base_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:55:01.949044Z",
     "iopub.status.busy": "2025-12-20T12:55:01.948820Z",
     "iopub.status.idle": "2025-12-20T12:55:01.956285Z",
     "shell.execute_reply": "2025-12-20T12:55:01.955668Z",
     "shell.execute_reply.started": "2025-12-20T12:55:01.949027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "importance = (\n",
    "    pd.Series(base_model.get_booster().get_score(importance_type=\"gain\"))\n",
    "    .rename(\"gain\")\n",
    ")\n",
    "\n",
    "importance = importance / importance.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:55:01.957665Z",
     "iopub.status.busy": "2025-12-20T12:55:01.956973Z",
     "iopub.status.idle": "2025-12-20T12:55:01.976094Z",
     "shell.execute_reply": "2025-12-20T12:55:01.975505Z",
     "shell.execute_reply.started": "2025-12-20T12:55:01.957644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "feature_stats = pd.DataFrame({\n",
    "    \"missing_frac\": missing_frac,\n",
    "    \"gain\": importance\n",
    "}).fillna(0)\n",
    "\n",
    "feature_stats.sort_values(\n",
    "    [\"gain\", \"missing_frac\"],\n",
    "    ascending=[False, True],\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-19T20:47:21.304814Z",
     "iopub.status.idle": "2025-12-19T20:47:21.305085Z",
     "shell.execute_reply": "2025-12-19T20:47:21.304988Z",
     "shell.execute_reply.started": "2025-12-19T20:47:21.304977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# DROP_MISSING = 0.9\n",
    "# MIN_GAIN = 0.001  # 0.1%\n",
    "\n",
    "# features_to_keep = feature_stats[\n",
    "#     ~(\n",
    "#         (feature_stats[\"missing_frac\"] > DROP_MISSING) &\n",
    "#         (feature_stats[\"gain\"] < MIN_GAIN)\n",
    "#     )\n",
    "# ].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T20:40:43.983300Z",
     "iopub.status.busy": "2025-12-19T20:40:43.982670Z",
     "iopub.status.idle": "2025-12-19T20:40:44.066519Z",
     "shell.execute_reply": "2025-12-19T20:40:44.065894Z",
     "shell.execute_reply.started": "2025-12-19T20:40:43.983276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# X_train = X_train[features_to_keep]\n",
    "# X_valid = X_valid[features_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:55:01.978005Z",
     "iopub.status.busy": "2025-12-20T12:55:01.977740Z",
     "iopub.status.idle": "2025-12-20T12:55:01.992439Z",
     "shell.execute_reply": "2025-12-20T12:55:01.991934Z",
     "shell.execute_reply.started": "2025-12-20T12:55:01.977984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# feature_stats must already exist\n",
    "# Columns expected:\n",
    "#   - missing_frac\n",
    "#   - gain\n",
    "\n",
    "feature_stats = feature_stats.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the best values of DROP_MISSING and MIN_GAIN using hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:01:58.954593Z",
     "iopub.status.busy": "2025-12-20T13:01:58.954088Z",
     "iopub.status.idle": "2025-12-20T13:01:58.962486Z",
     "shell.execute_reply": "2025-12-20T13:01:58.961767Z",
     "shell.execute_reply.started": "2025-12-20T13:01:58.954567Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from optuna.exceptions import TrialPruned\n",
    "import gc, torch, tqdm\n",
    "\n",
    "def expand_cat_features(cat_cols, all_columns):\n",
    "    expanded = []\n",
    "    for c in cat_cols:\n",
    "        expanded += [col for col in all_columns if col.startswith(f\"{c}_\")]\n",
    "    return expanded\n",
    "\n",
    "from optuna.exceptions import TrialPruned\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    drop_missing = trial.suggest_float(\"drop_missing\", 0.6, 0.95)\n",
    "    min_gain = trial.suggest_float(\"min_gain\", 1e-5, 1e-2, log=True)\n",
    "\n",
    "    # Feature selection\n",
    "    selected_features = feature_stats[\n",
    "        ~(\n",
    "            (feature_stats[\"missing_frac\"] > drop_missing) &\n",
    "            (feature_stats[\"gain\"] < min_gain)\n",
    "        )\n",
    "    ].index.tolist()\n",
    "\n",
    "    # Expand categorical features properly\n",
    "    cat_features_expanded = expand_cat_features(cat_cols, X_train.columns)\n",
    "\n",
    "    # Force keep expanded categorical features\n",
    "    selected_features = list(set(selected_features).union(cat_features_expanded))\n",
    "\n",
    "    if len(selected_features) < 50:\n",
    "        raise TrialPruned()\n",
    "\n",
    "    X_tr = X_train[selected_features]\n",
    "    X_va = X_valid[selected_features]\n",
    "    \n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "        enable_categorical=True,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=24,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        n_estimators=100,\n",
    "        eval_metric=\"auc\"\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_tr, y_train,\n",
    "        eval_set=[(X_va, y_valid)],\n",
    "        early_stopping_rounds=20,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    preds = model.predict_proba(X_va)[:, 1]\n",
    "\n",
    "    # -------------------------\n",
    "    # GPU CLEANUP (CRITICAL)\n",
    "    # -------------------------\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    y_valid_df = pd.DataFrame(y_valid, columns = [\"target\"])\n",
    "    preds_df = pd.DataFrame(preds, columns = [\"prediction\"])\n",
    "    return amex_metric(y_valid_df, preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:02:02.210885Z",
     "iopub.status.busy": "2025-12-20T13:02:02.210025Z",
     "iopub.status.idle": "2025-12-20T13:02:02.384671Z",
     "shell.execute_reply": "2025-12-20T13:02:02.383931Z",
     "shell.execute_reply.started": "2025-12-20T13:02:02.210848Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# Remove references to Optuna internals\n",
    "del study\n",
    "\n",
    "# Clean Python memory\n",
    "gc.collect()\n",
    "\n",
    "# Release CUDA memory\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-12-20T13:02:05.433987Z",
     "iopub.status.busy": "2025-12-20T13:02:05.433156Z",
     "iopub.status.idle": "2025-12-20T13:19:17.868194Z",
     "shell.execute_reply": "2025-12-20T13:19:17.867526Z",
     "shell.execute_reply.started": "2025-12-20T13:02:05.433955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import optuna, tqdm, time\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "best_drop_missing = study.best_params[\"drop_missing\"]\n",
    "best_min_gain = study.best_params[\"min_gain\"]\n",
    "\n",
    "print(best_drop_missing, best_min_gain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:31:48.646787Z",
     "iopub.status.busy": "2025-12-20T13:31:48.646458Z",
     "iopub.status.idle": "2025-12-20T13:31:48.653466Z",
     "shell.execute_reply": "2025-12-20T13:31:48.652515Z",
     "shell.execute_reply.started": "2025-12-20T13:31:48.646754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build mapping once\n",
    "cat_feature_map = {}\n",
    "\n",
    "for c in cat_cols:\n",
    "    cat_feature_map[c] = [\n",
    "        col for col in X_train.columns\n",
    "        if col.startswith(f\"{c}_\")\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:32:04.886413Z",
     "iopub.status.busy": "2025-12-20T13:32:04.886131Z",
     "iopub.status.idle": "2025-12-20T13:32:04.890606Z",
     "shell.execute_reply": "2025-12-20T13:32:04.889995Z",
     "shell.execute_reply.started": "2025-12-20T13:32:04.886392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "forced_cat_features = []\n",
    "\n",
    "for c in cat_cols:\n",
    "    forced_cat_features.extend(cat_feature_map.get(c, []))\n",
    "\n",
    "selected_features = list(set(selected_features).union(forced_cat_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:32:23.307471Z",
     "iopub.status.busy": "2025-12-20T13:32:23.306778Z",
     "iopub.status.idle": "2025-12-20T13:32:23.311561Z",
     "shell.execute_reply": "2025-12-20T13:32:23.310989Z",
     "shell.execute_reply.started": "2025-12-20T13:32:23.307447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    f for f in selected_features\n",
    "    if f in X_train.columns\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:32:55.828395Z",
     "iopub.status.busy": "2025-12-20T13:32:55.827717Z",
     "iopub.status.idle": "2025-12-20T13:32:55.842746Z",
     "shell.execute_reply": "2025-12-20T13:32:55.841781Z",
     "shell.execute_reply.started": "2025-12-20T13:32:55.828372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_tr = X_train[selected_features]\n",
    "X_va = X_valid[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:32:36.457392Z",
     "iopub.status.busy": "2025-12-20T13:32:36.456646Z",
     "iopub.status.idle": "2025-12-20T13:32:36.474658Z",
     "shell.execute_reply": "2025-12-20T13:32:36.473754Z",
     "shell.execute_reply.started": "2025-12-20T13:32:36.457364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "selected_features = feature_stats[\n",
    "    ~(\n",
    "        (feature_stats[\"missing_frac\"] > best_drop_missing) &\n",
    "        (feature_stats[\"gain\"] < best_min_gain)\n",
    "    )\n",
    "].index.tolist()\n",
    "\n",
    "selected_features = list(set(selected_features).union(cat_cols))\n",
    "\n",
    "X_tr = X_train[selected_features]\n",
    "X_va = X_valid[selected_features]\n",
    "\n",
    "print(\"Final feature count:\", len(selected_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T12:10:00.288429Z",
     "iopub.status.busy": "2025-12-20T12:10:00.287696Z",
     "iopub.status.idle": "2025-12-20T12:10:00.299105Z",
     "shell.execute_reply": "2025-12-20T12:10:00.298104Z",
     "shell.execute_reply.started": "2025-12-20T12:10:00.288402Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SHAP based keep/drop logic\n",
    "ref_model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cuda\",\n",
    "    enable_categorical=True,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_estimators=300,\n",
    "    eval_metric=\"auc\"\n",
    ")\n",
    "\n",
    "ref_model.fit(\n",
    "    X_train[selected_features],\n",
    "    y_train,\n",
    "    eval_set=[(X_valid[selected_features], y_valid)],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T20:22:14.338025Z",
     "iopub.status.busy": "2025-12-19T20:22:14.337766Z",
     "iopub.status.idle": "2025-12-19T20:22:14.993855Z",
     "shell.execute_reply": "2025-12-19T20:22:14.992840Z",
     "shell.execute_reply.started": "2025-12-19T20:22:14.338007Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "trial_history = []\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"missing\": np.nan,\n",
    "        \"enable_categorical\": True,\n",
    "        \"n_estimators\": 500,\n",
    "\n",
    "        # ---- Parameters to tune ----\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 8, 80, step=8),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 10, 100, step=10),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.05, 0.1]),\n",
    "        \"subsample\": trial.suggest_categorical(\"subsample\", [0.3, 0.4, 0.5, 0.8, 1.0]),\n",
    "        \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", [0.5, 0.8, 1.0]),\n",
    "        \n",
    "\n",
    "        # ---- Regularization tuning ----\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 5, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # predictions\n",
    "    preds = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    # Compute AMEX\n",
    "    y_true_df = pd.DataFrame({'target': y_valid}).reset_index(drop=True)\n",
    "    y_pred_df = pd.DataFrame({'prediction': preds}).reset_index(drop=True)\n",
    "\n",
    "    score = amex_metric(y_true_df, y_pred_df)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # SAVE TRIAL RESULTS SAFELY\n",
    "    # ----------------------------\n",
    "    trial_history.append({\n",
    "        \"params\": params.copy(),              # <-- IMPORTANT FIX\n",
    "        \"best_iteration\": model.best_iteration,\n",
    "        \"amex_score\": score\n",
    "    })\n",
    "    \n",
    "    return score  # Optuna will maximize the AMEX metric\n",
    "\n",
    "\n",
    "# Run study\n",
    "study = optuna.create_study(\n",
    "    study_name=\"xgb_amex_aggregated\",\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///optuna_xgb.db\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=50)  # adds 300 more\n",
    "\n",
    "# Convert to DataFrame\n",
    "trial_df = pd.DataFrame(trial_history)\n",
    "\n",
    "# Flatten params dict into columns (optional but very useful!)\n",
    "trial_df = trial_df.join(trial_df[\"params\"].apply(pd.Series)).drop(columns=[\"params\"])\n",
    "\n",
    "trial_df.sort_values(\"amex_score\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"Best AMEX:\", study.best_trial.value)\n",
    "print(\"Best Params:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T20:16:12.702329Z",
     "iopub.status.busy": "2025-12-19T20:16:12.701547Z",
     "iopub.status.idle": "2025-12-19T20:16:12.706493Z",
     "shell.execute_reply": "2025-12-19T20:16:12.705632Z",
     "shell.execute_reply.started": "2025-12-19T20:16:12.702304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"missing\": np.nan,\n",
    "    \"enable_categorical\": True,\n",
    "    \"device\": \"cuda\",\n",
    "\n",
    "    \"max_depth\": 80,\n",
    "    \"min_child_weight\": 40,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "\n",
    "    \"lambda\": 0.007670118758441345,\n",
    "    \"alpha\": 0.09157175965761555,\n",
    "    \"gamma\": 1.028865262384579,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T20:16:15.235710Z",
     "iopub.status.busy": "2025-12-19T20:16:15.235039Z",
     "iopub.status.idle": "2025-12-19T20:17:03.022454Z",
     "shell.execute_reply": "2025-12-19T20:17:03.021831Z",
     "shell.execute_reply.started": "2025-12-19T20:16:15.235685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "final_model = xgb.XGBClassifier(\n",
    "    **best_params,\n",
    "    n_estimators=500  # intentionally large\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_metric=amex_metric_xgb,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:34:42.171964Z",
     "iopub.status.busy": "2025-12-20T13:34:42.171316Z",
     "iopub.status.idle": "2025-12-20T13:34:45.428573Z",
     "shell.execute_reply": "2025-12-20T13:34:45.427964Z",
     "shell.execute_reply.started": "2025-12-20T13:34:42.171940Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Drop the columns with missing fraction > 0.5\n",
    "cols_to_drop = df_agg.columns[df_agg.isna().mean() > 0.83].tolist()\n",
    "# Create the modified dataframe\n",
    "df_agg= df_agg.drop(columns=cols_to_drop)\n",
    "\n",
    "#denoise\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df_agg = denoise_numeric(df_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:35:03.878747Z",
     "iopub.status.busy": "2025-12-20T13:35:03.877892Z",
     "iopub.status.idle": "2025-12-20T13:35:03.884501Z",
     "shell.execute_reply": "2025-12-20T13:35:03.883627Z",
     "shell.execute_reply.started": "2025-12-20T13:35:03.878690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "agg_cat_cols = [col for col in df_agg.columns if any(col.startswith(cat) for cat in cat_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:35:06.023238Z",
     "iopub.status.busy": "2025-12-20T13:35:06.022661Z",
     "iopub.status.idle": "2025-12-20T13:35:06.070307Z",
     "shell.execute_reply": "2025-12-20T13:35:06.069470Z",
     "shell.execute_reply.started": "2025-12-20T13:35:06.023212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_agg_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:35:09.434899Z",
     "iopub.status.busy": "2025-12-20T13:35:09.434559Z",
     "iopub.status.idle": "2025-12-20T13:35:09.455065Z",
     "shell.execute_reply": "2025-12-20T13:35:09.454282Z",
     "shell.execute_reply.started": "2025-12-20T13:35:09.434875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for c in agg_cat_cols:\n",
    "    df_agg_merged[c] = df_agg_merged[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:35:10.551462Z",
     "iopub.status.busy": "2025-12-20T13:35:10.550656Z",
     "iopub.status.idle": "2025-12-20T13:35:10.614439Z",
     "shell.execute_reply": "2025-12-20T13:35:10.613847Z",
     "shell.execute_reply.started": "2025-12-20T13:35:10.551435Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = df_agg_merged.drop(['customer_ID', 'target'], axis=1)\n",
    "y = df_agg_merged['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:35:12.271291Z",
     "iopub.status.busy": "2025-12-20T13:35:12.271000Z",
     "iopub.status.idle": "2025-12-20T13:35:12.509078Z",
     "shell.execute_reply": "2025-12-20T13:35:12.508166Z",
     "shell.execute_reply.started": "2025-12-20T13:35:12.271269Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T13:35:14.023790Z",
     "iopub.status.busy": "2025-12-20T13:35:14.023244Z",
     "iopub.status.idle": "2025-12-20T14:50:16.286445Z",
     "shell.execute_reply": "2025-12-20T14:50:16.285524Z",
     "shell.execute_reply.started": "2025-12-20T13:35:14.023766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "trial_history = []\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"missing\": np.nan,\n",
    "        \"enable_categorical\": True,\n",
    "\n",
    "        # ---- Parameters to tune ----\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 8, 48, step=8),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 20, 50, step=10),\n",
    "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [0.05, 0.1]),\n",
    "        \"subsample\": trial.suggest_categorical(\"subsample\", [0.5, 0.8, 1.0]),\n",
    "        \"colsample_bytree\": trial.suggest_categorical(\"colsample_bytree\", [0.5, 0.8, 1.0]),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [200, 400]),\n",
    "\n",
    "        # ---- Regularization tuning ----\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 10, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 5, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # predictions\n",
    "    preds = model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    # Compute AMEX\n",
    "    y_true_df = pd.DataFrame({'target': y_valid}).reset_index(drop=True)\n",
    "    y_pred_df = pd.DataFrame({'prediction': preds}).reset_index(drop=True)\n",
    "\n",
    "    score = amex_metric(y_true_df, y_pred_df)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # SAVE TRIAL RESULTS SAFELY\n",
    "    # ----------------------------\n",
    "    trial_history.append({\n",
    "        \"params\": params.copy(),              # <-- IMPORTANT FIX\n",
    "        \"best_iteration\": model.best_iteration,\n",
    "        \"amex_score\": score\n",
    "    })\n",
    "    \n",
    "    return score  # Optuna will maximize the AMEX metric\n",
    "\n",
    "\n",
    "# Run study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Convert to DataFrame\n",
    "trial_df = pd.DataFrame(trial_history)\n",
    "\n",
    "# Flatten params dict into columns (optional but very useful!)\n",
    "trial_df = trial_df.join(trial_df[\"params\"].apply(pd.Series)).drop(columns=[\"params\"])\n",
    "\n",
    "trial_df.sort_values(\"amex_score\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"Best AMEX:\", study.best_trial.value)\n",
    "print(\"Best Params:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T12:11:44.744158Z",
     "iopub.status.busy": "2025-11-19T12:11:44.743801Z",
     "iopub.status.idle": "2025-11-19T12:11:46.960625Z",
     "shell.execute_reply": "2025-11-19T12:11:46.959614Z",
     "shell.execute_reply.started": "2025-11-19T12:11:44.744134Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for col in ['max_depth', 'min_child_weight', 'learning_rate', 'subsample', \n",
    "            'colsample_bytree', 'n_estimators', 'lambda', 'alpha', 'gamma']:\n",
    "    \n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.scatterplot(data=trial_df, x=col, y='amex_score')\n",
    "    plt.title(f'{col} vs AMEX')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:06:37.856489Z",
     "iopub.status.busy": "2025-12-20T15:06:37.856047Z",
     "iopub.status.idle": "2025-12-20T15:06:37.861371Z",
     "shell.execute_reply": "2025-12-20T15:06:37.860509Z",
     "shell.execute_reply.started": "2025-12-20T15:06:37.856456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:08:41.008934Z",
     "iopub.status.busy": "2025-12-20T15:08:41.008217Z",
     "iopub.status.idle": "2025-12-20T15:10:58.560034Z",
     "shell.execute_reply": "2025-12-20T15:10:58.559395Z",
     "shell.execute_reply.started": "2025-12-20T15:08:41.008908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"missing\": np.nan,\n",
    "        \"enable_categorical\": True,\n",
    "\n",
    "        # ---- tuned params ----\n",
    "        \"max_depth\": 48,\n",
    "        \"min_child_weight\": 30,\n",
    "        \"learning_rate\":0.05,\n",
    "        \"subsample\": 1.0,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"n_estimators\": 10000,\n",
    "        \"lambda\": 1.2899531383219924, \n",
    "        \"alpha\": 1.3441815317991856, \n",
    "        \"gamma\": 3.066108845170049,\n",
    "        \"eval_metric\": \"auc\"\n",
    "    }\n",
    "\n",
    "best_xgb = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "best_xgb.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        early_stopping_rounds=150,\n",
    "\n",
    "        verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:11:30.819340Z",
     "iopub.status.busy": "2025-12-20T15:11:30.818644Z",
     "iopub.status.idle": "2025-12-20T15:11:30.822673Z",
     "shell.execute_reply": "2025-12-20T15:11:30.822120Z",
     "shell.execute_reply.started": "2025-12-20T15:11:30.819317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:17:04.939092Z",
     "iopub.status.busy": "2025-12-20T15:17:04.938426Z",
     "iopub.status.idle": "2025-12-20T15:17:05.993806Z",
     "shell.execute_reply": "2025-12-20T15:17:05.992970Z",
     "shell.execute_reply.started": "2025-12-20T15:17:04.939064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "thresholds = np.linspace(0.0, 1.0, 200)\n",
    "scores = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_label = (preds >= t).astype(int)\n",
    "    scores.append(f1_score(y_true, y_pred_label))\n",
    "\n",
    "best_idx = np.argmax(scores)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_f1 = scores[best_idx]\n",
    "\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "print(\"Best F1:\", best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:17:10.290219Z",
     "iopub.status.busy": "2025-12-20T15:17:10.289641Z",
     "iopub.status.idle": "2025-12-20T15:17:10.475510Z",
     "shell.execute_reply": "2025-12-20T15:17:10.474904Z",
     "shell.execute_reply.started": "2025-12-20T15:17:10.290191Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_true, preds)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision–Recall Curve\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:17:14.515010Z",
     "iopub.status.busy": "2025-12-20T15:17:14.514403Z",
     "iopub.status.idle": "2025-12-20T15:17:14.678108Z",
     "shell.execute_reply": "2025-12-20T15:17:14.677499Z",
     "shell.execute_reply.started": "2025-12-20T15:17:14.514987Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_true, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:17:19.098791Z",
     "iopub.status.busy": "2025-12-20T15:17:19.098461Z",
     "iopub.status.idle": "2025-12-20T15:17:22.381440Z",
     "shell.execute_reply": "2025-12-20T15:17:22.380699Z",
     "shell.execute_reply.started": "2025-12-20T15:17:19.098767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_label = (preds >= t).astype(int)\n",
    "    precisions.append(precision_score(y_true, y_pred_label))\n",
    "    recalls.append(recall_score(y_true, y_pred_label))\n",
    "    f1s.append(f1_score(y_true, y_pred_label))\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(thresholds, precisions, label=\"Precision\")\n",
    "plt.plot(thresholds, recalls, label=\"Recall\")\n",
    "plt.plot(thresholds, f1s, label=\"F1 Score\")\n",
    "plt.axvline(best_threshold, color='black', linestyle='--', label=f\"Best t={best_threshold:.3f}\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Threshold Tuning Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:17:25.930404Z",
     "iopub.status.busy": "2025-12-20T15:17:25.929926Z",
     "iopub.status.idle": "2025-12-20T15:17:26.112980Z",
     "shell.execute_reply": "2025-12-20T15:17:26.112137Z",
     "shell.execute_reply.started": "2025-12-20T15:17:25.930379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred_best = (preds >= best_threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred_best)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(f\"Confusion Matrix (Best threshold = {best_threshold:.3f})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:17:34.696622Z",
     "iopub.status.busy": "2025-12-20T15:17:34.696097Z",
     "iopub.status.idle": "2025-12-20T15:17:34.720383Z",
     "shell.execute_reply": "2025-12-20T15:17:34.719806Z",
     "shell.execute_reply.started": "2025-12-20T15:17:34.696600Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Convert probabilities to labels\n",
    "y_pred_best = (preds >= best_threshold).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred_best)\n",
    "prec = precision_score(y_true, y_pred_best)\n",
    "rec = recall_score(y_true, y_pred_best)\n",
    "f1 = f1_score(y_true, y_pred_best)\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold:.4f}\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:21:18.932081Z",
     "iopub.status.busy": "2025-12-20T15:21:18.931816Z",
     "iopub.status.idle": "2025-12-20T15:21:18.937223Z",
     "shell.execute_reply": "2025-12-20T15:21:18.936581Z",
     "shell.execute_reply.started": "2025-12-20T15:21:18.932061Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame({'prediction': preds}).reset_index(drop=True)\n",
    "y_true = pd.DataFrame({'target': y_valid}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-20T15:21:20.427212Z",
     "iopub.status.busy": "2025-12-20T15:21:20.426948Z",
     "iopub.status.idle": "2025-12-20T15:21:20.452657Z",
     "shell.execute_reply": "2025-12-20T15:21:20.452040Z",
     "shell.execute_reply.started": "2025-12-20T15:21:20.427192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "g = normalized_weighted_gini(y_true, y_pred)\n",
    "d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "print(g, d, 0.5 * (g + d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When all the statements are aggregated\n",
    "- The best threshold for deciding whether it's gonna default or not is 0.3518\n",
    "- Accuracy = 0.8971\n",
    "- Precision = 0.7827\n",
    "- Recall = 0.8394\n",
    "- F1 Score = 0.8101\n",
    "- Amex Score = 0.7754\n",
    "- AUC = 0.9565\n",
    "- Normalized Weighted Gini = 0.9103\n",
    "- Percentage of total defaulters captured in Top Four Percent= 0.6378\n",
    "  \n",
    "  Note that these metrics are on validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When only the last statement is considered\n",
    "- The best threshold for deciding whether it's gonna default or not is 0.3518\n",
    "- Accuracy = 0.8871\n",
    "- Precision = 0.7426\n",
    "- Recall = 0.8696\n",
    "- F1 Score = 0.8011\n",
    "- Amex Score = 0.7728\n",
    "- AUC = 0.9552\n",
    "- Normalized Weighted Gini = 0.9103\n",
    "- Percentage of total defaulters captured in Top Four Percent= 0.6354\n",
    "  \n",
    "  Note that these metrics are on validation data."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 3723648,
     "sourceId": 35332,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
